下面是一套**在纯 CPU 环境**下，用「DeepSeek 小参数开源模型」做**文本场景分类**的完整落地方案。内容涵盖：总体路线对比与推荐、模型架构与训练方式、数据集设计与标注规范、监督学习与反馈闭环、推理与部署、评估与校准，以及可打印的**架构示意图**（ASCII & Mermaid 二选一都给到）。

---

# 一、整体路线与推荐

你要做的是“根据用户反馈进行场景分类”。在纯 CPU 的约束下，我们优先考虑**算力友好的训练方式**，并保留后续可迭代空间。给出四种路线，并标注优先级：

1. **特征提取 + 线性头（Linear Probe）【推荐起步】**

* 冻结 DeepSeek 小模型全部参数，仅在其**某一层隐藏状态的池化向量**上训练一个 Logistic Regression / MLP 分类头。
* 训练极快、对 CPU 友好；上线后可秒级迭代；效果常常已能覆盖大多数业务场景。

2. **LoRA 微调分类化输出（指令化/生成式分类）【第二步升级】**

* 在解码器（LM）上加 **LoRA 低秩适配**，把输出约束为你定义的**标签词**或\*\*\<label\_x>**特殊标记，做**监督微调\*\*。
* 比 1) 稍慢，但仍可在 CPU 上完成（选 1B\~3B 量级模型，低 rank、低序列长）。

3. **P-Tuning v2 / Prefix-Tuning（参数更少）【替代 LoRA】**

* 只优化少量前缀向量，进一步降低训练成本；效果与 LoRA 接近，取决于数据量与任务。

4. **全参数微调（不建议在纯 CPU）**

* 纯 CPU 强行全量微调会非常慢，无必要。

**建议流程**：
先用【路线1】快速拿到可用基线 → 若准确率或可解释性不足，再升级到【路线2】或【路线3】。

**核心思路**：在纯CPU的严格约束下，采用**渐进式策略**，优先选择算力友好、迭代迅速的方案，用最小成本验证可行性，再逐步升级。

以下是四种技术路线的深度对比与选型建议：

| 特性 | **路线1: 特征提取+线性头** | **路线2: LoRA微调（生成式）** | **路线3: P-Tuning v2** | **路线4: 全参数微调** |
| :--- | :--- | :--- | :--- | :--- |
| **核心思想** | 冻结大模型，作特征提取器，仅训练分类头 | 冻结大模型，注入可训练低秩矩阵，进行指令微调 | 冻结大模型，在输入前加可训练前缀向量引导模型 | 更新全部模型参数 |
| **训练速度** | ⭐⭐⭐⭐⭐ **极快 (分钟-小时级)** | ⭐⭐ **慢 (小时-天级)** | ⭐⭐ **慢 (小时-天级)** | ⭐ **极慢 (周级)，不可行** |
| **推理速度** | ⭐⭐⭐⭐⭐ **极快 (毫秒级，一次前向传播)** | ⭐⭐ **慢 (需自回归生成)** | ⭐⭐ **慢 (需自回归生成)** | ⭐⭐ **慢** |
| **CPU资源消耗** | ⭐⭐⭐⭐⭐ **极低** | ⭐⭐⭐ **低** | ⭐⭐⭐⭐ **极低** | ⭐ **不可接受** |
| **实现复杂度** | ⭐⭐⭐⭐⭐ **非常简单** | ⭐⭐ **复杂 (需构建指令/处理生成)** | ⭐⭐⭐ **中等** | ⭐⭐⭐ **中等** |
| **效果上限** | ⭐⭐⭐ **较高 (依赖预训练特征质量)** | ⭐⭐⭐⭐⭐ **高 (模型适配任务，潜力大)** | ⭐⭐⭐⭐ **中高 (通常稍逊于LoRA)** | ⭐⭐⭐⭐⭐ **最高** |
| **灵活性** | ⭐⭐ **低 (仅限分类)** | ⭐⭐⭐⭐⭐ **高 (易扩展为生成任务)** | ⭐⭐⭐⭐ **中高** | ⭐⭐⭐⭐⭐ **高** |
| **推荐优先级** | **⭐⭐⭐⭐⭐ (首选)** | **⭐⭐⭐⭐ (次选)** | **⭐⭐⭐ (备选)** | **⭐ (弃用)** |

**最终推荐路线**：
1.  **【首选启动】路线1：特征提取 + 线性头**。用最高效的方式建立**强基线模型**，快速验证数据质量和方案可行性。
2.  **【效果升级】路线2：LoRA指令化微调**。当基线性能遇到瓶颈时启用，以更高的训练成本换取性能提升，并为未来生成解释等需求留出空间。
3.  **【备选对比】路线3：P-Tuning v2**。可作为路线2的替代方案进行对比实验，但其稳定性和表现通常略逊于LoRA。

---

# 二、模型设计与输入输出

## 2.1 分类范式两种思路

**A. 生成式分类（指令化）**

*   **设计**： 把分类任务重构为“让模型根据指令输出一个标签词”。
*   **输入**： `[指令] + [选项] + [文本] + [输出引导]`。
*   **输出**： 严格限定为预定义标签之一（如“售后”）。
*   **优点**： 任务表述自然，易扩展至多任务（如同时生成分类和摘要）。
*   **缺点**： **推理需生成，速度慢；需后处理保证输出格式正确**。
*   **适用**： 对准确率要求极高，或未来有交互、解释需求的场景。


**B. 判别式分类（线性头）**

*   **设计**： 用 LM 作特征抽取器，顶上一个线性/MLP 分类头，直接输出 logits → softmax。
*   **输入**： 原始文本（无需指令模板）。
*   **输出**： 各类别的概率分布（softmax）。
*   **优点**： **推理极快，部署简单，是标准分类API**。
*   **缺点**： 灵活性差，仅为分类任务服务。
*   **适用**： **追求高吞吐、低延迟的生产环境主力分类器**。


> **推荐**：先 B 后 A。B 当主力生产分类器，A 用于人机交互和灰度验证/解释。

## 2.2 输入输出格式建议

### 生成式（A）

**Prompt 模板**（简化示例）：

```
[System] 你是一个场景分类助手。只输出一个标签，不要解释。
[Labels] 允许的标签: {旅行, 支付, 物流, 售后, 账户, 其他}
[User] {原始文本}
[Output] 请选择一个标签：
```

**输出**：

* 严格为 `{旅行|支付|物流|售后|账户|其他}` 之一。
* 推理时可用**贪心解码 + 正则截断**，或**对每个标签求 P(标签|输入)** 后取 argmax（label-word scoring）。

### 判别式（B）

**特征构造**：

*   **Tokenizer**：  将文本 tokenize，取 LM 中间层（如 L/2 层或最后一层）的\*\*\[last token 或 mean pooling]\*\*隐藏状态作为句向量 h。
*   **特征提取**： 取最后一层隐藏状态，进行**均值池化（Mean Pooling）**，得到句向量 `h ∈ R^d`。
*   **分类头**： `logits = W * h + b`，输出即为各类别分数。

---

# 三、数据集与监督训练

## 3.1 是否需要监督训练？

* **需要。**你要“根据用户反馈做场景分类”，天然属于**监督学习**（有标签）。
* 若冷启动无标签，可用**零样本/少样本生成式**先跑一版，**人工校对**形成首批金标，再进行监督训练。

## 3.2 标签体系（Taxonomy）

* **互斥**：同一条只属于一个最细标签。
* **层级化**（可选）：一级（大场景）→ 二级（子场景）；先训练一级平层分类，再做二级。
* **“其他/不确定”**：必须有；并规定触发规则（置信度低于阈值或覆盖不到时）。

## 3.3 数据格式（JSONL 推荐）

```json
{"text": "无法登录账户，提示密码错误", "label": "账户"}
{"text": "付款后订单一直未发货", "label": "物流"}
{"text": "申请退款但不到账", "label": "支付"}
```

* 训练/验证/测试划分：70/15/15（或 8/1/1）。
* 至少每类 300\~1000 条起步；长尾类允许更少，但**注意重采样/类权重**。
* 去重、脱敏（手机号、订单号等替换为占位符）。

## 3.4 质量与增强

* **一致性审查**：同义问题同类；跨标注者一致性 ≥ 0.8。
* **数据增强**（可选）：同义改写、噪声注入（表情/口头语）、多渠道文本（App 留言/客服单）。
* **负样本**：引入无关文本，防止过拟合。

---

# 四、训练细节（纯 CPU）

## 4.1 环境与模型选择

* **模型**：选择 DeepSeek 的**小参数**（1B\~3B 量级）中文/多语模型；上下文长度 ≥ 2k。`deepseek-ai/deepseek-coder-1.3b`（通用能力强）或 `Qwen1.5-1.8B`（中文优化佳）。首选1.3B-3B参数模型。
* **框架**：PyTorch CPU（MKL/oneDNN）、PEFT（LoRA/P-Tuning）、Transformers。**设置环境变量以榨干CPU性能**：
    ```bash
    export OMP_NUM_THREADS=<物理核心数> # 控制并行计算线程数
    export MKL_NUM_THREADS=<物理核心数> # 优化数学库性能
    ```
* **线程**：`OMP_NUM_THREADS`, `MKL_NUM_THREADS` 与 CPU 物理核数匹配。
* **精度**：CPU 下多为 FP32；若支持 BF16/INT8 亦可尝试（oneDNN INT8 推理）。
* **序列长度**：尽量裁剪到 256\~512；过长会显著拖慢训练。

## 4.2 路线 1：特征提取 + 线性头

* **前向**：冻结 LM，取倒数第 1\~2 层隐藏状态做 mean-pool → `h ∈ R^d`。 冻结LM → 前向传播得隐藏状态 → 均值池化 → 训练分类头。
* **分类头**：

  * Logistic Regression：`d × C` 参数量极小。
  * 或 1 层 MLP（ReLU + Dropout 0.1）。
* **超参**：

    *   `batch_size`: 32-64 (根据内存调整)
    *   `LR（分类头）`: 1e-3 ~ 3e-3
    *   `Epochs`: 10-20 (监控验证集损失早停)
    *   `Optimizer`: AdamW
    *   `Loss`: CrossEntropyLoss (类别不平衡时设置 `class_weight`)
  
* **优点**：训练分钟~~小时级；推理毫秒~~十毫秒级/条（视模型与序列长）。

## 4.3 路线 2：LoRA 微调（生成式分类）

* **目标**：让模型对指令只输出合法标签。
* **做法**：

  * 挑选 `q_proj`, `v_proj`（以及 `k/o` 可选）做 LoRA；
  * `rank r = 4~8`，`alpha = 16~32`，`dropout = 0.05`；
  * 冻结其余参数；
  * 训练数据用**指令式样本**（见 2.2 A）。
* **解码约束**：

  * 采用**label-word scoring**（对每个标签计算条件概率，选最大）；
  * 或 beam=1 贪心 + **词表掩码**（只允许标签词 token）。
* **超参**：

  * LR：5e-5 \~ 1e-4（仅 LoRA）；Batch size：4~~16；Seq Len：≤512；Epoch：3~~5。
* **注意**：bitsandbytes 的 NF4/QLoRA 多依赖 GPU；纯 CPU 下直接 LoRA（FP32）即可，保持模型小、r 小。

## 4.4 路线 3：P-Tuning v2 / Prefix-Tuning
* **Prefix长度**: 20-100 (可视为虚拟Token，越长能力越强，开销越大)。
* **超参**： 参考PEFT库官方示例，学习率一般略高于LoRA。

* **仅优化少量可学习前缀**，内存/算力更省；
* **其它同 LoRA**，但实现选用 PEFT 的 PrefixTuning。

---

# 五、评估、校准与上线阈值

## 5.1 指标

* **整体**：Accuracy、Macro-F1（类不平衡建议主看 Macro-F1）。
* **按类**：每类 Precision/Recall/F1。
* **鲁棒性**：错别字/口语化；跨主题干扰；超长/超短文本。

## 5.2 置信度与拒识

* 判别式：`max softmax` 作为置信度；
* 生成式：标签条件概率或对数几率。
* **阈值**：低于 τ（如 0.55\~0.7）→ 输出 “其他/不确定” 或**触发人工复核**。

## 5.3 校准

* 验证集上做**温度缩放**（Temperature Scaling）；必要时做**阈值 per-class** 调整。

---

# 六、基于用户反馈的闭环（主动学习）

1. **线上收集**：保存（文本, 预测标签, 置信度, 时间, 会话ID, 业务结果/用户纠正）。
2. **优先挑选**：不确定（接近阈值）或错分高风险样本，进入**标注队列**。
3. **增量更新**：

   * 路线 1：只重训**线性头**即可（分钟级）。
   * 路线 2/3：小批量 LoRA/Prefix 继续训练 + **少量旧数据回放**（防遗忘）。
4. **灰度发布**：A/B 对比旧版；监控线上 Macro-F1、拒识率、人工介入率。

---

# 七、推理与部署（纯 CPU）

* **判别式（推荐生产）**：

  * 预加载 LM（冻结）、分类头；
  * **批量推理**（B=8\~64）+ 缓存 tokenizer；
  * oneDNN/MKL 打开多线程；
  * **剪短文本**到任务相关的 max\_len（如 256）。

* **生成式（解释/联动）**：

  * 使用 label-word scoring，避免长解码；
  * 或采用 **llama.cpp/GGML** 将模型量化到 INT4/INT8 做线上推理（LoRA 合并后再量化）。

* **接口**：

  * REST（FastAPI）或 gRPC；
  * 返回：`label`, `confidence`, `topk`, `explain`（可选显示最相近 few-shot 示例或关键 n-gram）。

---

# 八、最小可行训练计划（一天内拿到可用版本）

1. 定义标签集（6\~12 个一级标签，含“其他”）。
2. 准备 3k\~10k 条金标（或 1k 启动 + 线上收敛）。
3. 路线 1：提取隐藏层 → 训练 Logistic/MLP 头（5\~10 epoch）。
4. 评估与温度缩放；设拒识阈值。
5. 部署 CPU 推理服务；打通反馈采集。
6. 若线上 F1 不足，再做 LoRA 指令化微调（路线 2）并与路线 1 融合（如“若置信度低则走生成式复核”）。

---

# 九、超参与实践细则（便于直接抄用）

* **Tokenizer**：与 DeepSeek 模型配套；统一大小写与全半角；URL/数字可规约化。
* **池化**：mean-pool（mask 掉 padding）；或取最后 token hidden；二者择优。
* **正则化**：Dropout=0.1；L2=1e-5。
* **优化器**：AdamW；判别式 LR=1e-3；LoRA LR=8e-5；`weight_decay=0.01`。
* **学习率调度**：线性 warmup 5% steps，再余弦退火或恒定。
* **早停**：验证集 Macro-F1 3 次不提升即停。
* **类别不平衡**：

  * 类权重 = `1/log(1.02 + freq)`；
  * 或采样：少类过采/多数类下采；
  * 或 Focal Loss（γ=2, α=按类权重）。
* **文本长度**：P95 长度作为 max\_len，过长裁剪（保留关键信息区域）。

---

# 十、架构示意图

## 10.1 ASCII 版（可直接粘到文档/PRD）

```
          ┌──────────────────────────────────────────┐
          │              数据采集与标注              │
          │  用户反馈/对话 → 清洗/脱敏 → 人工标注    │
          └───────────────┬──────────────────────────┘
                          │ JSONL(train/val/test)
                          ▼
┌───────────────────────────────────────────────────────────────────┐
│                         训练与评估（CPU）                          │
│ ┌───────────────────────────┐   ┌───────────────────────────────┐ │
│ │ 路线1: 特征提取+线性头    │   │ 路线2: LoRA 指令化微调        │ │
│ │  DeepSeek(冻结)           │   │  DeepSeek(+LoRA)              │ │
│ │    ↓ hidden states(pool)  │   │  prompt→生成标签(受限解码)    │ │
│ │  线性/MLP 分类头          │   │  CrossEntropy(label-words)    │ │
│ │  CrossEntropy             │   │                               │ │
│ └──────────┬───────────────┘   └──────────┬────────────────────┘ │
│            │   指标: Acc / Macro-F1 / 校准 / 阈值                 │
└────────────┼──────────────────────────────────────────────────────┘
             │                                   ▲  纠错/不确定样本
             ▼                                   │
┌────────────────────────────────────────────────┴───────────────┐
│                         部署与推理（CPU）                        │
│  REST/gRPC                                                   │
│  判别式主干：DeepSeek(冻结)+分类头 → label, confidence        │
│  低置信度 → 生成式复核：指令化 prompt → 标签校验               │
│  温度缩放/阈值/拒识 → 人工复核 → 写回反馈库                    │
└───────────────────────────────────────────────────────────────┘
```

## 10.2 Mermaid（如果你的平台支持渲染）

```mermaid
flowchart TD
  A[用户反馈/对话日志] --> B[清洗/脱敏/去重]
  B --> C[人工标注/质检]
  C --> D[JSONL 数据集 划分 train/val/test]

  subgraph E[训练与评估（CPU）]
    D --> F1[路线1: DeepSeek 冻结→池化→线性/MLP 头]
    D --> F2[路线2: DeepSeek + LoRA 指令化微调]
    F1 --> G[评估: Acc/Macro-F1/校准/阈值]
    F2 --> G
  end

  G --> H[部署（CPU 推理服务）]
  H --> I{置信度 >= 阈值?}
  I -- 是 --> J[返回标签与置信度]
  I -- 否 --> K[生成式复核(受限解码)]
  K --> L{仍不确定?}
  L -- 是 --> M[人工复核/回标]
  L -- 否 --> J
  M --> N[反馈库/主动学习样本池]
  N --> E
```

---

# 十一、你可能关心的 FAQ

* **Q：需要把输入/输出“变形”成标准分类模型吗？**

  * 若走**判别式路线**（推荐生产）：不需要“变形”，就是标准文本分类（特征→logits→softmax）。
  * 若走**生成式路线**：建议把输出**严格限制为固定标签集合**（label-word 或 `<label_x>` 特殊 token），并在后处理做**映射与校验**，这就成了“标准分类器的生成式皮肤”。

* **Q：一定要监督训练吗？**

  * 是的，想要稳定的“场景分类”能力，**监督数据是关键**。零/少样本只用于冷启动与过渡。

* **Q：纯 CPU 会不会太慢？**

  * 选小模型（1B\~3B）、裁短序列（≤512）、冻结主体只训小头或 LoRA，**完全能跑通**。上线推理也可通过 **INT8/INT4 量化**与**批处理**保障延迟。

---

# 十二、交付清单（你可以按此执行）

1. **标签定义文档**（含判定标准、边界案例）。
2. **数据集**（JSONL，脱敏，train/val/test）。
3. **路线 1 脚本**：特征提取 + 线性头训练、评估、导出。
4. **路线 2 脚本**：LoRA 指令化微调、受限解码推理。
5. **服务部署**：FastAPI/gRPC，返回 `label, confidence, topk, reason(optional)`。
6. **监控与反馈**：线上仪表盘（F1、拒识率、人工介入率）、主动学习样本池。
7. **文档**：环境、参数、阈值、回滚与灰度流程。

